# Assignment 4: Multimodal Processing

This assignment consists of the following:
* [Image_Captioning](image_captioning.ipynb), where you'll read one of the classic image captioning papers and answer some questions about their architecture. You'll use CLIP to create a zero shot image classifier.  Finally, you'll experiment with the BLIP image captioner to describe some images and see how CLIP categorizes the content of images.
* [answers](answers) file where you'll put all your answers (except C5 and D5)



## Submission Instructions

As with Assignment 3, please submit by running the submit.sh script, only with `-a 4` (since this is assignment 4).
```
./assignment/submit.sh -u your-github-username -a 4
```

It is your responsibility to check that your work has made it to your GitHub repository in the `a4-submit` branch.  Remember that we will grade by looking at the content of your answers file as well as your notebook.

As always, a small number of points are awarded in each assignment for submitting in the right place. We will give each person who correctly submits their assignment one point on this homework assignment. We will also give one point to each person who submits an answer file that is parseable by the autograder (e.g. properly filled out as you did in a0 and a1).
